#+TITLE: 扩散模型
* 背景
** 主要内容
- 应用场景
  - dall-e2
  - imagen
  - sora
- 数学基础回顾
- 参考：
  + https://erdem.pl/2023/11/step-by-step-visual-introduction-to-diffusion-models
  + https://medium.com/@kemalpiro/step-by-step-visual-introduction-to-diffusion-models-235942d2f15c
** 机器学习里面有几种任务
*** 机器学习中常见的任务
- 分类
- 回归
*** 我们之前熟悉的概率建模
- 基于特征来推断目标事件发生的概率。P(label|特征）
- ctr 里面：基于用户和item的特征信息来推测用户点击item的概率

   $P(y=1|x)=\sigma(f_{\theta}(x))$

- NLP 中的相关性模型：基于用户输入的query和doc特征来推测两者相关的概率
   $P(y=1|(q,t))=\sigma(f_{\theta}(q,t))$

- 我们很少需要对特征的分布直接建模
  + 用户特征的分布？
  + query,doc 的特征分布？
*** 概率密度估计
机器学习中另外一个大的topic是概率密度的估计：
- 假设概率分布的pdf，然后做参数估计
  + 假设这个分布是gaussian，来推断mu, sigma
- 例子：
  + language model:
    + token粒度，每个token有离散的值    $P(x_{1}, x_{2},\ldots, x_{n})= P(x_{1})P(x_{2}|x_{1})\ldots P(x_{n}|x_{1,\ldots,n-1})$
    + autoregressive
    + decoder only GPT model
  + image model?
    + pixelRNN
    + 效率的问题: 1920*1080=207,3600
*** 做概率密度估计有啥用？
- 建模出来一个概率密度函数pdf $P_{\theta}(x)$ 
  + 知道什么样的x概率低，知道什么样的x概率高
- 有啥用？
  + 基于概率采样，我们可以生成更多的类似的，不在样本集合中的 X
  + 图片：比如登录的图片认证，生成若干旋转的文字，角度等等，这些应该是单纯随机生成的
- conditional 的时候会产生大的价值
  + 文本：LLM GPT做的就是概率密度估计的事情，可以逐个token来生成
  + 图片：更进一步，做可以控制的图像生成，如果加一个conditional，P(x) P(x|c), 可以做文本到图像的生成
** 关于生成模型的直接建模
*** 如果直接建模
- 使用范围局限：
  + 基于这个$P_{\theta}(x)$ 采样
  + 无法做更多的复杂生成的事情，无法对对生成做细粒度操控
  + 比如，
    + 我想加入一段文字的描述来生成
    + 我想生成某种特定类型，特定的风格的图片
*** 直接建模的难点？
- 图像本省的高维特性
- sample 的效率：高维空间中的sample效率会很低
- 你的建模需要能建模出来像素之间的依赖性
- 直接来建模pdf是一个非常困难的事情
** 换个一种思路：先验分布+确定性函数来建模
*** 先验分布+确定性函数来建模
- prior z:
  + 没有需要学习的参数
  + 在一个低维度的latent space中采样
- 确定性函数：
  + h(z)
*** 理论依据
- 理论的依据：先验的gauss + 确定性的函数 可以表征任意的分布。
*** 用处
- - 有什么用呢？
** 关于图像的生成
** 图像生成的两种思路
*** 自回归的方式
**** 像素级别的自回归
- PixelRNN/PixelCNN
**** patch级别的自回归
*** 扩散的方式

** 扩散模型概览
** 条件扩散模型
This forms the backbone of image super-resolution models such as Cascaded Diffusion Models [18]
* 数学基础回顾
** 概率论的公式回顾
*** 先验
*** 后验
*** 似然性
*** 联合概率
*** 
** 蒙特卡洛方法
*** 定义
*** 一个简单的例子：计算pi
*** 缺点：在高维空间中效率非常的低
*** 本质上：在高维空间里面，你的采样到的大部分的点都不是你想要的
*** 大数定律：均值可以
换句话说，随着样本大小 n 无限增加，样本均值几乎肯定会等于总体均值 μ。
** 高斯分布的性质
*** 定义
*** 性质
*** linear gaussian

** 随机变量
*** reparameterization trick
如果你对随机变量来做期望，同时这个随机变量里面还有参数的时候，你对随机变量求导基本做不了，需要使用这个trick，记得在强化学习中野

* 马尔科夫链
*** 定义
*** 性质
** 变分 and Jensen's Inequality
* Generative Model
** Generative Model
*** 正常的模型是怎么做概率建模的？
思考清楚一个样本的概率，然后做概率的最大化。
$P(x)$
** 生成模型的概率建模
- 每个样本对应一个latent variable $(x, z)$
- $P(x)=\int_{z} P(x,z) dz=\int_{z}P(x|z)P(z)dz$
*** 如何做最大化？
- 积分的存在，没法直接优化
*** 改用MC 方法？
- $P(x) = E_{z\in P(z)}P(x|z) P(z) dz = \sum_{i} P(x_i|z_i)P(z_i)$
*** 如何来解决？
** variational auto encoder
** ELBO backbone
*** 背景
$P(x)=\int P(x|z) p(z)$
直接做主要的困难来源于MC在高维空间中的sample的效率问题
*** 引入Q分布
1. 聚焦有意义的 z 值
2. Q(z∣X)：为此，我们引入了一个新的函数 
Q(z∣X)，这是一个编码器网络，它可以基于观察到的数据 
X 提供一个关于 z 值的分布。这个分布专门针对那些可能产生 
X 的 z 值。变分方法使得这个分布可以通过学习数据来逼近真实的后验分布 
P(z∣X)。
*** formula
$\log P(X) - D_{KL}[Q(z|X) \| P(z|X)] = \mathbb{E}_{z \sim Q}[\log P(X|z)] - D_{KL}[Q(z|X) \| P(z)]$

* 扩散模型
** 什么是扩散模型
** 为什么要多步来生成
** 优化的目标函数
** ELBO的定义
* 简单的扩散模型
* 简单的扩展模型的代码
#+begin_src python
import torch
import torch.nn as nn
import torch.optim as optim

class UNet(nn.Module):
    def __init__(self, in_channels, out_channels, time_embedding_size):
        super(UNet, self).__init__()
        # Define the UNet architecture with time conditioning
        # This is a placeholder structure, you can make it more complex
        self.time_embedding = nn.Linear(time_embedding_size, out_channels)
        
        self.encoder = nn.Sequential(
            nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, out_channels, kernel_size=3, stride=1, padding=1),
        )
    
    def forward(self, x, t):
        # Embed the time step
        t_embed = self.time_embedding(t).unsqueeze(-1).unsqueeze(-1)
        # Apply the encoder
        encoded = self.encoder(x)
        # Combine time and space information
        encoded = encoded + t_embed
        # Apply the decoder
        return self.decoder(encoded)

# Hyperparameters
in_channels = 3  # For RGB images
out_channels = 3  # Predicting noise for RGB images
time_embedding_size = 16
T = 1000  # Total number of time steps

# Model, optimizer, and loss function
model = UNet(in_channels=in_channels, out_channels=out_channels, time_embedding_size=time_embedding_size)
optimizer = optim.Adam(model.parameters())
loss_fn = nn.MSELoss()

# Training loop
def train(model, optimizer, loss_fn, T, steps=10000, image_size=(64, 64)):
    for step in range(steps):
        model.train()

        # Sample x_0 from data distribution q(x_0) (placeholder for actual data)
        x_0 = torch.randn(1, in_channels, *image_size)  # Normally you'd have a batch of data points

        # Sample t uniformly from {1, ..., T}
        t = torch.randint(1, T + 1, (1,)).long()

        # Sample epsilon from N(0, I)
        epsilon = torch.randn_like(x_0)

        # Predict noise using the model
        epsilon_pred = model(x_t=x_0, t=t)

        # Calculate loss as per algorithm (gradient descent step)
        loss = loss_fn(epsilon_pred, epsilon)

        # Perform gradient descent
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # Print loss every 100 steps
        if step % 100 == 0:
            print(f"Step {step}, Loss: {loss.item()}")

# Run training
train(model=model, optimizer=optimizer, loss_fn=loss_fn, T=T)

#+end_src
